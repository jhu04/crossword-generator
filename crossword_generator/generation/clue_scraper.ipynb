{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clue Scraper\n",
    "\n",
    "Sources include [XWord Info](https://www.xwordinfo.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "import generation.constants as const\n",
    "\n",
    "headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246\"}\n",
    "\n",
    "def scrape(urls):\n",
    "    \"\"\"Scrapes all pages in `urls` from the same site.\"\"\"\n",
    "    site_names = [url.split('.')[1].lower() for url in urls]\n",
    "    site_name = site_names[0]\n",
    "    assert all(n == site_name for n in site_names)\n",
    "\n",
    "    file_name = f'scraped-clues-{site_name}.csv'\n",
    "    path = os.path.join(const.DATA_PATH, file_name)\n",
    "    if not os.path.exists(path):\n",
    "        pd.DataFrame(columns=['clue', 'answer', 'url']).to_csv(path, index=False)\n",
    "\n",
    "    for url in tqdm(urls):\n",
    "        r = requests.get(url=url, headers=headers)\n",
    "        soup = BeautifulSoup(r.content, 'html5lib')\n",
    "        data = []\n",
    "\n",
    "        if site_name == 'xwordinfo':\n",
    "            table = soup.find('div', attrs={'class': 'numclue'})\n",
    "            for row in table.find_all('div'):\n",
    "                txt = row.get_text()\n",
    "                try:\n",
    "                    clue, answer = txt.split(\" : \")\n",
    "                    data.append([clue, answer, url])\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        pd.DataFrame(data, columns=['clue', 'answer', 'url']).to_csv(path, mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8412/8412 [54:29<00:00,  2.57it/s]  \n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "xwordinfo_dates = pd.date_range(start=\"2000-01-01\", end=datetime.today()).to_pydatetime().tolist()\n",
    "xwordinfo_urls = [f\"https://www.xwordinfo.com/Crossword?date={date.month}/{date.day}/{date.year}\" for date in xwordinfo_dates]\n",
    "\n",
    "scrape(xwordinfo_urls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crossify39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "374f21b6971a4d7456200b1a3977c127532e739364fc68f7938a4df050a83c38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
